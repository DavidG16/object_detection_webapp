{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c8554c-f33a-4615-9da2-537b289fedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai import Detection\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffe543d-85a7-4455-b59f-24b631637500",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = f\"{Path(os.getcwd()).parent}/model/yolo.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae671b7-2ea9-4658-bc03-ab34403e0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dgrijalva/envs/ml1/lib/python3.9/site-packages/keras/layers/normalization.py:524: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "yolo = Detection.ObjectDetection()\n",
    "yolo.setModelTypeAsYOLOv3()\n",
    "yolo.setModelPath(modelpath)\n",
    "yolo.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d121c3-d0df-4579-a26c-9a57192932f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0) #0=front-cam, 1=back-cam\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1300)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ba643c-512a-4bcd-9ff8-e5b499574593",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Ensure you specified correct input image, input type, output type and/or output image path ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/imageai/Detection/__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[0;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                         out_boxes, out_scores, out_classes = self.sess.run(\n\u001b[0m\u001b[1;32m    832\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__yolo_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__yolo_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__yolo_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4f03a3f65f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m## predict yolo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     img, preds = yolo.detectCustomObjectsFromImage(input_image=img, \n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"array\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"array\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/ml1/lib/python3.9/site-packages/imageai/Detection/__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[0;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[1;32m    916\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdetected_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_objects_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    919\u001b[0m                     \"Ensure you specified correct input image, input type, output type and/or output image path \")\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Ensure you specified correct input image, input type, output type and/or output image path "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ## read frames\n",
    "    ret, img = cam.read()\n",
    "    ## predict yolo\n",
    "    img, preds = yolo.detectCustomObjectsFromImage(input_image=img, \n",
    "                      custom_objects=None, input_type=\"array\",\n",
    "                      output_type=\"array\",\n",
    "                      minimum_percentage_probability=70,\n",
    "                      display_percentage_probability=False,\n",
    "                      display_object_name=True)\n",
    "    ## display predictions\n",
    "    cv2.imshow(\"\", img)\n",
    "    ## press q or Esc to quit    \n",
    "    if (cv2.waitKey(1) & 0xFF == ord(\"q\")) or (cv2.waitKey(1)==27):\n",
    "        break\n",
    "## close camera\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de824c-de52-48b7-843c-86ce6da60eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze -> reqs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827ea570-02fc-425f-b909-a6835b2d0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "! Python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14baabf3-e078-4800-b2f9-40ad97fc16f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
